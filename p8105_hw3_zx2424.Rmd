---
title: "p8105_hw3_zx2424"
author: "Zhaoqianyu Xiong"
date: "2022-10-15"
output: github_document
---
```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1
```{r}
data("instacart")
```

Make a dataframe based on the "instacart" dataset. 
```{r}
instacart = 
  instacart %>% 
  as_tibble(instacart)
```
The size of the dataset is 1384617*15. Its variables contain information relating to id of order, product, user, department and aisle; name of the product, aisle and department. Also, order in which each product was added into cart, the order sequence number of the user, the day of the week on which the order was placed, the hour of the day on which the order was placed, days of the last order can be learned from the data. Taking the first row of the dataset for example, a customer whose id number is 112108 firstly added Bulgarian Yogurt (id = 49302) into the cart, which belongs to yogurt aisle (id = 120) and daily eggs department (id = 16). The purchase happened on Thursday, 10 am. Days since the last order of the customer is 9.

There are 134 different aisles. And the most items are ordered from fresh vegetables.
```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Make a plot that shows the number of items ordered in each aisle.
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Make a table showing three most popular items in each of the aisles.
```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered.
```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

## Problem 2
Load, tidy and otherwise wrangle the data. 
```{r}
accel = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names()  %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "time_minute",
    names_prefix = "activity_",
    values_to = "activity") %>%
  mutate(weekday_vs_weekend = ifelse(day == "Sunday" | day == "Saturday", "weekend", "weekday"),
  time_minute = as.integer(time_minute),
  day = factor(day, levels = str_c(c("Mon", "Tues", "Wednes", "Thurs", "Fri", "Satur", "Sun"), "day"))) %>%
  arrange(day_id, time_minute)
```
The resulting dataset includes variables "week", "day_id", "day", "time_minute", "activity", "weekday_vs_weekend". I introduced new variable "time_minute" to show the exact time (count by minute) of the recorded activity. This dataset has `r nrow(accel)` observations.

Total activity for each day
```{r}
accel %>%
  group_by(day_id) %>%
  summarize(total = sum(activity)) %>%
  arrange(day_id) %>%
  knitr::kable()
```
The trend is not apparent for total activity for each day.

When making the plot for 35 days separately using geom_line(), the plot is too messy and tendency cannot be seen clearly. 
```{r}
accel %>%
  ggplot(aes(x = time_minute, y = activity, group = day_id, color = day)) +
  geom_line() +
  labs(
    title = "24_hour activity time courses for each day",
    x = "the xth minute of the day",
  )
```

Therefore, I use geom_smooth() to make the plot for different days of the week. It can be concluded that for all the days in the week, activity was lower at night (from 0th to 400th minute), perhaps because of sleeping. In the daytime, activities of most days fluctuated slightly except Sunday and Friday. For Friday, average activity reached a high level in the evening (from 1200th to 1300th) minute; While it arrived at its peak in the morning (between 500th to 700th minute) on Sunday.
```{r}
accel %>%
  ggplot(aes(x = time_minute, y = activity, color = day)) +
  geom_smooth(se = FALSE) +
  labs(
    title = "24_hour activity time courses for each day",
    x = "the xth minute of the day",
  )
```

## Problem 3
```{r}
library(p8105.datasets)
data("ny_noaa")

ny_noaa
```
The size of original dataset is 2595176*7. Key variables include weather station ID, date of observation, precipitation (tens of mm), snowfall (mm), snow depth (mm), maximum temperature (tens of degrees C), and minimum temperature (tens of degree C). A great amount of data is missing for this dataset, reaching `r sum(is.na(ny_noaa))`.

Data cleaning. The original units for temperature is tens of degree C, which is not commonly used. So I converted it into degree C. On the other hand, because the units for precipitation(mm) and snowfall(mm) are reasonable, I left them unchanged.
```{r}
ny_noaa_tidy = 
ny_noaa %>%
  janitor::clean_names() %>%
  separate(col = date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = as.integer(month)) %>%
  mutate(year = as.integer(year)) %>%
  mutate(day = as.integer(day)) %>%
  mutate(tmax = as.integer(tmax)/10) %>%
  mutate(tmin = as.integer(tmin)/10)
```